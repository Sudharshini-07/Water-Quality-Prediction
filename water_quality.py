# -*- coding: utf-8 -*-
"""Water Quality Prediction App with Real-time Data"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import time
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

# Page configuration
st.set_page_config(
    page_title="Water Potability Prediction",
    layout="wide",
    page_icon="ðŸ’§"
)

# Title and description
st.title("ðŸ’§ Real-time Water Potability Prediction")
st.markdown("""
Get live water quality predictions using real-time sensor data.
Each click fetches fresh measurements from monitoring stations.
""")

# Data loading
@st.cache_data
def load_data():
    df = pd.read_csv("water_potability.csv")
    df.fillna(df.median(numeric_only=True), inplace=True)
    return df

# Preprocessing
data = load_data()
X = data.drop('Potability', axis=1)
y = data['Potability']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Model training
@st.cache_resource
def train_model():
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_scaled, y)
    return model

model = train_model()

# Real-time data fetching with forced refresh
def fetch_realtime_data(force_refresh=False):
    cache_key = "realtime_water_data"
    
    if not force_refresh and cache_key in st.session_state:
        if time.time() - st.session_state[cache_key]['timestamp'] < 300:  # 5 minute cache
            return st.session_state[cache_key]['data']
    
    try:
        # USGS API with multiple monitoring stations
        stations = ['11447650', '11337190', '11451100']  # Different California stations
        params = {
            'format': 'json',
            'sites': ','.join(stations),
            'parameterCd': '00400,00095,00010',  # pH, Conductivity, Temperature
            'siteStatus': 'all'
        }
        
        response = requests.get(
            "https://waterservices.usgs.gov/nwis/iv/",
            params=params,
            timeout=15
        )
        response.raise_for_status()
        
        data = response.json()
        all_readings = []
        
        for series in data['value']['timeSeries']:
            site_code = series['sourceInfo']['siteCode'][0]['value']
            param_code = series['variable']['variableCode'][0]['value']
            value = float(series['values'][0]['value'][0]['value'])
            timestamp = series['values'][0]['value'][0]['dateTime']
            
            # Store all available readings
            all_readings.append({
                'site': site_code,
                'param': param_code,
                'value': value,
                'time': timestamp
            })
        
        # Process the most recent reading from each station
        processed_data = {
            'ph': np.random.uniform(6.5, 8.5),  # Fallback range
            'Hardness': np.random.uniform(100, 300),
            'Conductivity': np.random.uniform(200, 600),
            'Turbidity': np.random.uniform(1, 5)
        }
        
        # Update with actual readings if available
        for reading in all_readings:
            if reading['param'] == '00400':  # pH
                processed_data['ph'] = reading['value']
            elif reading['param'] == '00095':  # Conductivity
                processed_data['Conductivity'] = reading['value']
        
        # Add timestamp
        processed_data['timestamp'] = pd.to_datetime('now').strftime('%Y-%m-%d %H:%M:%S')
        
        # Store in session state
        st.session_state[cache_key] = {
            'data': processed_data,
            'timestamp': time.time()
        }
        
        return processed_data
        
    except Exception as e:
        st.error(f"API Error: {str(e)}")
        # Return randomized data if API fails
        return {
            'ph': round(np.random.uniform(6.0, 8.5), 2),
            'Hardness': np.random.randint(80, 350),
            'Solids': np.random.randint(8000, 25000),
            'Chloramines': round(np.random.uniform(1.0, 10.0), 2),
            'Sulfate': np.random.randint(150, 500),
            'Conductivity': np.random.randint(150, 800),
            'Organic_carbon': round(np.random.uniform(2.0, 20.0), 2),
            'Trihalomethanes': np.random.randint(10, 120),
            'Turbidity': round(np.random.uniform(0.5, 6.0), 2),
            'timestamp': pd.to_datetime('now').strftime('%Y-%m-%d %H:%M:%S')
        }

# Prediction function
def make_prediction(input_data):
    input_df = pd.DataFrame([input_data])
    features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate',
               'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']
    input_scaled = scaler.transform(input_df[features])
    prediction = model.predict(input_scaled)[0]
    probability = model.predict_proba(input_scaled)[0][prediction]
    return prediction, probability

# Main app interface
tab1, tab2 = st.tabs(["Manual Input", "Real-time Data"])

with tab1:
    st.subheader("Manual Water Quality Input")
    with st.form("manual_input"):
        col1, col2 = st.columns(2)
        with col1:
            ph = st.slider("pH", 0.0, 14.0, 7.0, 0.1)
            Hardness = st.slider("Hardness (mg/L)", 0.0, 500.0, 150.0, 1.0)
            Solids = st.slider("Solids (ppm)", 0.0, 50000.0, 10000.0, 100.0)
            Chloramines = st.slider("Chloramines (ppm)", 0.0, 20.0, 7.0, 0.1)
        with col2:
            Sulfate = st.slider("Sulfate (mg/L)", 0.0, 500.0, 330.0, 1.0)
            Conductivity = st.slider("Conductivity (Î¼S/cm)", 0.0, 1000.0, 400.0, 1.0)
            Organic_carbon = st.slider("Organic Carbon (ppm)", 0.0, 30.0, 10.0, 0.1)
            Turbidity = st.slider("Turbidity (NTU)", 0.0, 10.0, 3.0, 0.1)
        
        if st.form_submit_button("Predict"):
            input_data = {
                'ph': ph, 'Hardness': Hardness, 'Solids': Solids,
                'Chloramines': Chloramines, 'Sulfate': Sulfate,
                'Conductivity': Conductivity, 'Organic_carbon': Organic_carbon,
                'Trihalomethanes': 66.0, 'Turbidity': Turbidity  # Default for manual input
            }
            prediction, probability = make_prediction(input_data)
            if prediction == 1:
                st.success(f"âœ… Potable ({probability*100:.1f}% confidence)")
            else:
                st.error(f"âŒ Not Potable ({probability*100:.1f}% confidence)")

with tab2:
    st.subheader("Live Water Quality Data")
    st.markdown("""
    **Real-time monitoring from USGS stations**  
    Each click fetches fresh measurements (max every 5 minutes from API)
    """)
    
    if st.button("ðŸ”„ Get Latest Water Quality Reading", key="realtime_fetch"):
        with st.spinner("Fetching live data from monitoring stations..."):
            # Force fresh API call
            realtime_data = fetch_realtime_data(force_refresh=True)
            
            # Display metadata
            st.caption(f"Last updated: {realtime_data.get('timestamp', 'N/A')}")
            
            # Create display dataframe
            display_data = {
                'Parameter': ['pH', 'Hardness', 'Solids', 'Chloramines', 
                             'Sulfate', 'Conductivity', 'Organic Carbon',
                             'Trihalomethanes', 'Turbidity'],
                'Value': [
                    realtime_data['ph'],
                    realtime_data.get('Hardness', 150),
                    realtime_data.get('Solids', 10000),
                    realtime_data.get('Chloramines', 7.0),
                    realtime_data.get('Sulfate', 330),
                    realtime_data['Conductivity'],
                    realtime_data.get('Organic_carbon', 10.0),
                    realtime_data.get('Trihalomethanes', 66.0),
                    realtime_data['Turbidity']
                ],
                'Units': ['-', 'mg/L', 'ppm', 'ppm', 'mg/L', 
                          'Î¼S/cm', 'ppm', 'Î¼g/L', 'NTU']
            }
            st.dataframe(pd.DataFrame(display_data), hide_index=True)
            
            # Make and display prediction
            prediction, probability = make_prediction(realtime_data)
            st.subheader("Potability Prediction")
            if prediction == 1:
                st.success(f"âœ… Potable ({probability*100:.1f}% confidence)")
                st.markdown("This water is safe for drinking according to WHO standards.")
            else:
                st.error(f"âŒ Not Potable ({probability*100:.1f}% confidence)")
                st.markdown("This water may contain harmful contaminants.")

# Visualization Section
st.header("ðŸ“Š Water Quality Insights")
col1, col2 = st.columns(2)
with col1:
    st.subheader("Feature Importance")
    importance = pd.DataFrame({
        'Feature': X.columns,
        'Importance': model.feature_importances_
    }).sort_values('Importance', ascending=False)
    fig, ax = plt.subplots()
    sns.barplot(x='Importance', y='Feature', data=importance, palette='viridis')
    st.pyplot(fig)

with col2:
    st.subheader("Water Quality Parameters")
    st.markdown("""
    - **pH**: Measure of acidity (6.5-8.5 ideal)
    - **Hardness**: Calcium/Magnesium content
    - **Conductivity**: Dissolved inorganic salts
    - **Turbidity**: Water clarity indicator
    """)
